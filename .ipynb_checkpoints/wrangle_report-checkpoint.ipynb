{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "> 1. Introduction\n",
    "> 2. Data Gathering\n",
    "> 3. Data Assessing\n",
    "> 4. Data Cleaning\n",
    "> 5. Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    ">  This Project involves getting data from a number of sources which are presented in different formats. Assessing the quality and tidiness before wrangling is aimed at induction to real world scenerio were data do not come clean. The tweet archive of Twitter user @dog_rates that rates people's dogs with a humorous comment about the dog would be used for this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Gathering\n",
    ">\n",
    ">In this section, I wrote codes to download files and additional data for my analysis. TWo of these files (twitter-archive-enhanced.csv and image-predictions.tsv) are available for download programatically from udacity servers.\n",
    ">\n",
    ">Also, I accessed the Twitter API to gather additional WeRateDogs Twitter data which was written to a tweet_json.txt file as an  addition to other two files. Afterwards, I read all three into my notebook as pandas dataframes as stated below:\n",
    ">\n",
    "> 1. twitter_archive_enhanced.csv loaded into df_dogs!\n",
    ">\n",
    "> 2. image_predictions.tsv loaded into df_image!\n",
    ">\n",
    "> 3. tweet_json.txt converted to csv and loaded into df_jsontext!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assessing Data\n",
    "dataframe was organised into subcategories and assessed visually and programmatically. These subcategories are:\n",
    "\n",
    "   A.   Assessing dataframe one (df_dogs) containing twitter_archive_enhanced.csv.\n",
    "\n",
    "   B.   Assessing dataframe two (df_image) containing image-predictions.tsv.\n",
    "\n",
    "   C.   Assessing dataframe three (df_jsontext) containing tweet_json.txt.\n",
    "  \n",
    "Issues hihlighted in bold were not delibrately cleaned and docummented in the notebook. However, the highlighted duplicates of 4 and 12 were cleaned when unnecessary columns were dropped before merging df_jsontext to master archive. Issue 1 was left uncleaned because i have met dogs with funny names in person!. A summerising list of issues detected from all three are:\n",
    "   \n",
    "### Quality issues\n",
    "\n",
    "  **1. Unsual names for dogs (e.g a, none) were found repeatedly in rows 2351, 2352, 2353, 2354 and 3255 of 'names' column  of df_dogs which indicates incorrect/invalid data.**\n",
    "\n",
    "\n",
    "2. Null values were found in columns of df_dogs which are in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id. and retweeted_status_timestamp.\n",
    "\n",
    "\n",
    "3.  wrong data format of data in 'source' column of df_dogs. Html tags are attached to URLs, turning them to jargon and hyperlinks\n",
    "\n",
    "\n",
    "4. Wrong datatype presented by 'timestamp' column of df_dogs which should be converted to dates.\n",
    "\n",
    "\n",
    "5. In df_dogs, tweet_ids with retweet values (retweeted_status_id) can duplicate the same dog picture in each retweet.\n",
    "\n",
    "\n",
    "6. In df_dogs, tweet_ids with in_reply_to_status_id can duplicate the same dog picture in each reply.\n",
    "\n",
    "\n",
    "7. In df_dogs, expanded_urls have 2297 non null-values, others are missing.\n",
    "\n",
    "\n",
    "8. P1, P2 and P3 columns of df_image with dog breed entries is inconsistent i.e Some entries have got underscore in them while some others are in sentence and lower cases.\n",
    "\n",
    "\n",
    "9. single image assigned to multiple tweet_ids by the 'jpg_url' column of df_image indicating data duplication.\n",
    "\n",
    "\n",
    "10. df_image is inadequate for analysis because data showing 'favourite count' was not included.\n",
    "\n",
    "\n",
    "11. df_image is inadequate for analysis due ommision of data accounting for 'retweet count'.\n",
    "\n",
    "\n",
    "**Observations** \n",
    "\n",
    "\n",
    "**12. 17 columns of df_jsontext have missing values, while 14 of these affected columns are missing staggering amount of such!.**\n",
    "\n",
    "### Tidiness issues\n",
    "12. (1) Data needed is fragmented into three different dataframes. Handling data is difficult without a merger of A and B.\n",
    "\n",
    "\n",
    "13. (2) Doggo, floofer, pupper, puppo columns of df_dogs describe a single variable-'dogtionary' hence, should heve been in the same column for tidyness.\n",
    "\n",
    "\n",
    "14. (3) clumsy data detected in row 1165 of df_dogs!. Dog descriptions and urls found in the same column(text column).\n",
    "\n",
    "**Observations** \n",
    "\n",
    "**4.'extended_entities' column of df_jsontext contains integers and strings which makes it difficult to handle data.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleaning Data\n",
    "Most issues detected during the assessing stages were resolved using the define, code and test precept. Merging, appending and concatenation was done to add new rows and columms formed from original but faulty ones. An example such is the formation of dogtionary column for tidyness.\n",
    "\n",
    "Also, '.astype', was used to change datatypes, numpy arrays were used to facilitate additions, '.loc' was used to slice data. Other tools deployed including the use of indexing, not logical and '.drop' were used to wrangle data to cleanliness. Finally, fragmentation of data was resolved by combining useeful data into twitter_archive_master.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusions\n",
    "\n",
    "The Twitter_archive_master.csv which was stored is the final product of my wrangling exercise. This file contain a number of issues regardless however, the scope of project allows for a minimum of 10 issues cleaning. Having satisfied this criteria, it was read into notebook for analysis and visualisations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
